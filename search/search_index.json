{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Services","text":"<p>If you are challenged with any of these areas, I can help:</p> <ul> <li>Understanding AI capabilities and limitations: What is possible now and in the near future.</li> <li>Retrieval-Augmented Generation (RAG): Implementing RAG with hybrid vector and semantic search with re-ranking. Including text, tabular data and images. Evaluating Embedding models.</li> <li>Generative AI hallucination: Understanding how to reduce and prevent hallucination.</li> <li>Evals (Evaluations): Understanding how to evaluate and have confidence in the content your Generative AI produces, including after changes.</li> <li>Generating high quality synthetic content: Using LLMs and hybrid RAG to generate accurate content.</li> <li>Prompt Engineering: Techniques to craft effective prompts for Generative AI.</li> <li>Image Generation: Understanding how diffusion models and latents are used in Generative AI.</li> <li>Quality Control: Maintaining consistency and reliability in Generative AI.</li> </ul>"},{"location":"#client-success-stories","title":"Client Success Stories","text":"Industry Challenge Solved Impact Automotive Content Generation through RAG pipeline 8x increase in content volume while enabling faster updates based on content changes Automotive Chatbot Neural Voices and Speech Transcription Reduced load on call centres and product experts Semiconductor Edge AI Super Resolution Meeting performance and quality requirements Publishing Technical publication review Ensuring quality of published material Universities AI Presentation and Workshop lesson review Ensuring quality and understandable course material"},{"location":"#who-i-am","title":"Who I Am","text":"<p>An experienced technical consultant specializing in generative AI implementation, with an academic AI background and cited research. I help teams, companies, and organizations:</p> <ul> <li>Build AI prototypes and solutions</li> <li>Solve problems using AI</li> <li>Implement AI in a future-proof manner with upgrades in mind</li> <li>Establish best practices for long-term success</li> <li>Advise on state-of-the-art tools and knowledge</li> </ul> <p>Read my Blog</p>"},{"location":"#testimonials","title":"Testimonials","text":"<p>Vice President, Compute Software (Technology Office) at Imagination Technologies. \u201cChris joined Imagination to consult in the area of deep learning, specifically super-resolution. He arrived with comprehensive knowledge of existing networks and their capabilities, supported by many previous technical posts on the subject. Chris was able to communicate effectively with research staff and navigate our engineering infrastructure to produce results quickly. I wouldn\u2019t hesitate to engage Chris again for consultation in this area; He is professional, articulate and a pleasure to work with.\u201d</p> <p>Solution Architect at a Global technology services and consulting company \u201cChris is one of the most competent, most imaginative problem-solvers I've come across. He's unafraid to tackle difficult technical matters, and I invariably seek his advice when faced with an issue. He's well-liked and respected across the whole company. I don't think I've ever seen Chris annoyed - he's preternaturally unflappable when everyone else around him is panicking. He's also great in front of clients, winning them over with ingenious solutions and clear explanations. He's obviously very intelligent and he keeps up-to-speed with latest technologies.\u201d</p> <p>CTO at Avostec \u201cChris is a seasoned developer with many years experience but more importantly, Chris is self-managing with a great understanding of the entire project and it's processes. His in-depth technical knowledge, approachable nature and his wide range of experience makes Chris an absolute pleasure to work with and manage. I would have no hesitancy in recommending Chris and comes highly recommended!\u201d</p>"},{"location":"blog/","title":"Blog","text":"<p>Welcome to my technical blog, where I share insights about:</p> <ul> <li>AI Innovation</li> <li>AI System Implementation</li> <li>Deep Learning Techniques</li> </ul>"},{"location":"blog/#stay-updated","title":"Stay Updated","text":"<p>Subscribe to receive AI technical insights, news, and best practices:</p> <p>Subscribe to Updates</p>"},{"location":"blog/2019/05/27/an-introduction-to-convolutional-neural-networks/","title":"An introduction to Convolutional Neural Networks","text":"<p>A Convolutional neural network (CNN) is a neural network that has one or more convolutional layers and are used mainly for image processing, classification, segmentation and also for other auto correlated data.</p> <p>An introduction to Convolutional Neural Networks</p>"},{"location":"blog/2019/03/14/save-time-resources-and-money-with-fine-tuning-existing-models/","title":"Save time, resources and money with fine tuning existing models.","text":"<p>This article describes experiments training a neural network to generate 3 channel colour images from single channel greyscale images using deep learning. In my opinion the results, whilst they vary by subject matter are astounding, with the model hallucinating what colours should be in the original subject matter.</p> <p>U-Net deep learning colourisation of greyscale images</p>"},{"location":"blog/2023/11/26/save-time-resources-and-money-with-latent-diffusion-based-image-generation/","title":"Save time, resources and money with Latent Diffusion based image generation.","text":"<p>This article shows a novel approach to training a generative model for image generation at reduced training times using latents and using a pre-trained ImageNet latent classifier as a component of the loss function.</p> <p>The image generation model was trained from an initialised (not pre-trained) state remarkably was less than 10 hours on a single desktop consumer NVIDIA card.</p> <p>Latent Diffusion and Perceptual Latent Loss</p>"},{"location":"blog/2020/02/21/insights-on-loss-function-engineering/","title":"Insights on loss function engineering.","text":"<p>These are a few insights on loss function engineering and deep neural network architectures that I\u2019ve gained from experimentation with using deep learning for various image processing techniques such as Super Resolution, Colourisation (inpainting colour into black and white images) and style transfer.</p> <p>Deep learning image enhancement insights on loss function engineering</p>"},{"location":"blog/2019/03/14/feature-based-loss-functions/","title":"Feature based loss functions","text":"<p>Loss functions using these techniques can be used during the training of U-Net based model architectures and could be applied to the training of other Convolutional Neural Networks that are generating an image as their predication/output.</p> <p>Loss functions based on feature activation and style loss.</p>"},{"location":"blog/2019/05/12/how-do-deep-neural-networks-work/","title":"How do Deep Neural Networks work?","text":"<p>Implementing deep learning has become accessible to so many more people and it helps to understand the fundamentals behind deep neural networks.</p> <p>The basics of Deep Neural Networks</p>"},{"location":"blog/2019/02/11/random-forests---a-free-lunch-thats-not-cursed/","title":"Random forests - a free lunch that\u2019s not cursed.","text":"<p>Random forests are one of a group of machine learning techniques called ensembles of decision trees, where essentially several decision trees are bagged together and take the average prediction. The other very effective technique in ensembles of decision trees group is Gradient boosting, which is in the boosting category rather than bagging category.</p> <p>Latent Diffusion and Perceptual Latent Loss</p>"},{"location":"blog/2021/01/31/rapid-prototyping-of-network-architectures-using-super-convergence-using-cyclical-learning-rate-schedules/","title":"Rapid prototyping of network architectures using Super-Convergence using Cyclical Learning Rate schedules.","text":"<p>Super-Convergence using Cyclical Learning Rate schedules is one of the most useful techniques in deep learning and very often overlooked. It allows for rapid prototyping of network architectures, loss function engineering, data augmentation experiments and training production ready models in orders of magnitude less training time and epochs</p> <p>Super Convergence with Cyclical Learning Rates in TensorFlow</p>"},{"location":"blog/2021/03/24/super-resolution-adobe-photoshop-versus-leading-deep-neural-networks/","title":"Super Resolution: Adobe Photoshop versus Leading Deep Neural Networks.","text":"<p>How effective is Adobe\u2019s Super Resolution compared to the leading super resolution deep neural network models? This article attempts to evaluate that and the results of Adobe\u2019s Super Resolution are very impressive.</p> <p>Super Resolution: Adobe Photoshop versus Leading Deep Neural Networks</p>"},{"location":"blog/2019/02/24/deep-learning-based-super-resolution-without-using-a-gan/","title":"Deep learning based super resolution, without using a GAN.","text":"<p>This article shows a novel approach to training a generative model for image generation at reduced training times using latents and using a pre-trained ImageNet latent classifier as a component of the loss function. Super resolution is the process of upscaling and or improving the details within an image. Often a low resolution image is taken as an input and the same image is upscaled to a higher resolution, which is the output. The details in the high resolution output are filled in where the details are essentially unknown.</p> <p>Deep learning based super resolution, without using a GAN</p>"},{"location":"blog/2019/09/09/tabular-data-analysis-with-deep-neural-nets/","title":"Tabular data analysis with deep neural nets.","text":"<p>Deep neural networks are now an effective technique for tabular data analysis, requiring little feature engineering and less maintenance than other techniques.</p> <p>Latent Diffusion and Perceptual Latent Loss</p>"},{"location":"blog/2019/03/14/u-nets-with-resnet-encoders-and-cross-connections/","title":"U-Nets with ResNet Encoders and cross connections","text":"<p>A U-Net architectures have cross connections similar to a DenseNet.</p> <p>U-Nets with ResNet Encoders and cross connections</p>"},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2021/","title":"2021","text":""},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/archive/2019/","title":"2019","text":""},{"location":"blog/page/2/","title":"Blog","text":""}]}